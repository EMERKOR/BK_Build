{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Ball Knower v1.1 - Calibration & Historical Backtest\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the Ball Knower v1.1 calibrated spread model.\n",
    "\n",
    "### Model Evolution:\n",
    "- **v1.0**: Deterministic model with fixed weights  \n",
    "  `spread = 0.02*nfelo_diff + 0.5*substack_diff + 35*epa_off_diff - 35*epa_def_diff`\n",
    "\n",
    "- **v1.1**: Calibrated weights learned from historical Vegas lines  \n",
    "  Uses ordinary least squares to find optimal weights that minimize error vs. Vegas\n",
    "\n",
    "### This Notebook:\n",
    "1. Load historical weeks (1-10 of 2025 season)\n",
    "2. Calibrate model weights using all historical games\n",
    "3. Evaluate correlation with Vegas lines\n",
    "4. Calculate Mean Absolute Error (MAE)\n",
    "5. Backtest Against-The-Spread (ATS) performance with edge thresholds\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Section 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import Ball Knower v1.1 calibration module\n",
    "from ball_knower.models.v1_1_calibration import (\n",
    "    calibrate_weights,\n",
    "    prepare_training_matrix,\n",
    "    build_week_lines_v1_1,\n",
    "    load_schedule_data\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Plot settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úì Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## Section 2: Configuration\n",
    "\n",
    "Define the historical weeks to use for calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "SEASON = 2025\n",
    "TRAINING_WEEKS = list(range(1, 11))  # Weeks 1-10\n",
    "\n",
    "print(f\"Calibration Configuration:\")\n",
    "print(f\"  Season: {SEASON}\")\n",
    "print(f\"  Training Weeks: {TRAINING_WEEKS}\")\n",
    "print(f\"  Total Weeks: {len(TRAINING_WEEKS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "calibrate-header",
   "metadata": {},
   "source": [
    "## Section 3: Calibrate Model Weights\n",
    "\n",
    "Use historical weeks to solve for optimal weights via ordinary least squares.\n",
    "\n",
    "The model solves:  \n",
    "`vegas_line ‚âà w_nfelo * nfelo_diff + w_substack * substack_diff + w_epa_off * epa_off_diff + w_epa_def * epa_def_diff + bias`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calibrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate weights using historical data\n",
    "weights = calibrate_weights(SEASON, TRAINING_WEEKS)\n",
    "\n",
    "print(\"\\nCalibrated Weights Summary:\")\n",
    "print(f\"  nfelo:          {weights['weight_nfelo']:.4f}\")\n",
    "print(f\"  substack:       {weights['weight_substack']:.4f}\")\n",
    "print(f\"  epa_offensive:  {weights['weight_epa_off']:.4f}\")\n",
    "print(f\"  epa_defensive:  {weights['weight_epa_def']:.4f}\")\n",
    "print(f\"  bias:           {weights['bias']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weights-comparison",
   "metadata": {},
   "source": [
    "### Comparison: v1.0 vs v1.1 Weights\n",
    "\n",
    "Let's compare the calibrated weights with the v1.0 fixed weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-weights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed weights from v1.0\n",
    "v1_0_weights = {\n",
    "    'weight_nfelo': 0.02,\n",
    "    'weight_substack': 0.5,\n",
    "    'weight_epa_off': 35.0,\n",
    "    'weight_epa_def': -35.0,\n",
    "    'bias': 0.0\n",
    "}\n",
    "\n",
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Component': ['nfelo', 'substack', 'epa_off', 'epa_def', 'bias'],\n",
    "    'v1.0 (Fixed)': [\n",
    "        v1_0_weights['weight_nfelo'],\n",
    "        v1_0_weights['weight_substack'],\n",
    "        v1_0_weights['weight_epa_off'],\n",
    "        v1_0_weights['weight_epa_def'],\n",
    "        v1_0_weights['bias']\n",
    "    ],\n",
    "    'v1.1 (Calibrated)': [\n",
    "        weights['weight_nfelo'],\n",
    "        weights['weight_substack'],\n",
    "        weights['weight_epa_off'],\n",
    "        weights['weight_epa_def'],\n",
    "        weights['bias']\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison['Difference'] = comparison['v1.1 (Calibrated)'] - comparison['v1.0 (Fixed)']\n",
    "comparison['% Change'] = (comparison['Difference'] / comparison['v1.0 (Fixed)'].replace(0, np.nan)) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"WEIGHT COMPARISON: v1.0 vs v1.1\")\n",
    "print(\"=\"*80)\n",
    "display(comparison)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "predictions-header",
   "metadata": {},
   "source": [
    "## Section 4: Generate Predictions on Training Data\n",
    "\n",
    "Apply calibrated weights to historical data to evaluate fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training matrix to get predictions\n",
    "X, y, games_df = prepare_training_matrix(SEASON, TRAINING_WEEKS)\n",
    "\n",
    "# Calculate v1.1 predictions\n",
    "X_with_bias = np.column_stack([X, np.ones(len(X))])\n",
    "w_vector = np.array([\n",
    "    weights['weight_nfelo'],\n",
    "    weights['weight_substack'],\n",
    "    weights['weight_epa_off'],\n",
    "    weights['weight_epa_def'],\n",
    "    weights['bias']\n",
    "])\n",
    "\n",
    "games_df['bk_line_v1_1'] = X_with_bias @ w_vector\n",
    "\n",
    "# Calculate v1.0 predictions\n",
    "games_df['bk_line_v1_0'] = (\n",
    "    0.02 * games_df['nfelo_diff'] +\n",
    "    0.5 * games_df['substack_power_diff'] +\n",
    "    35.0 * games_df['epa_off_diff'] +\n",
    "    -35.0 * games_df['epa_def_diff']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Generated predictions for {len(games_df)} games\")\n",
    "print(f\"\\nSample predictions:\")\n",
    "display(games_df[[\n",
    "    'week', 'away_team', 'home_team', \n",
    "    'vegas_line', 'bk_line_v1_1', 'bk_line_v1_0'\n",
    "]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correlation-header",
   "metadata": {},
   "source": [
    "## Section 5: Correlation Analysis\n",
    "\n",
    "Visualize how well our model predictions correlate with Vegas lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "corr_v1_1 = np.corrcoef(games_df['vegas_line'], games_df['bk_line_v1_1'])[0, 1]\n",
    "corr_v1_0 = np.corrcoef(games_df['vegas_line'], games_df['bk_line_v1_0'])[0, 1]\n",
    "\n",
    "# Create scatter plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# v1.1 plot\n",
    "ax1.scatter(games_df['vegas_line'], games_df['bk_line_v1_1'], alpha=0.6, s=50)\n",
    "ax1.plot([-15, 15], [-15, 15], 'r--', label='Perfect Agreement', linewidth=2)\n",
    "ax1.set_xlabel('Vegas Line', fontsize=12)\n",
    "ax1.set_ylabel('Ball Knower v1.1 Line', fontsize=12)\n",
    "ax1.set_title(f'v1.1 Calibrated Model\\nCorrelation: {corr_v1_1:.4f}', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# v1.0 plot\n",
    "ax2.scatter(games_df['vegas_line'], games_df['bk_line_v1_0'], alpha=0.6, s=50, color='orange')\n",
    "ax2.plot([-15, 15], [-15, 15], 'r--', label='Perfect Agreement', linewidth=2)\n",
    "ax2.set_xlabel('Vegas Line', fontsize=12)\n",
    "ax2.set_ylabel('Ball Knower v1.0 Line', fontsize=12)\n",
    "ax2.set_title(f'v1.0 Fixed Weights Model\\nCorrelation: {corr_v1_0:.4f}', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCorrelation with Vegas Lines:\")\n",
    "print(f\"  v1.1 (Calibrated): {corr_v1_1:.4f}\")\n",
    "print(f\"  v1.0 (Fixed):      {corr_v1_0:.4f}\")\n",
    "print(f\"  Improvement:       {corr_v1_1 - corr_v1_0:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mae-header",
   "metadata": {},
   "source": [
    "## Section 6: Mean Absolute Error (MAE)\n",
    "\n",
    "Calculate prediction error relative to Vegas lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE for both models\n",
    "mae_v1_1 = np.mean(np.abs(games_df['vegas_line'] - games_df['bk_line_v1_1']))\n",
    "mae_v1_0 = np.mean(np.abs(games_df['vegas_line'] - games_df['bk_line_v1_0']))\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_v1_1 = np.sqrt(np.mean((games_df['vegas_line'] - games_df['bk_line_v1_1']) ** 2))\n",
    "rmse_v1_0 = np.sqrt(np.mean((games_df['vegas_line'] - games_df['bk_line_v1_0']) ** 2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREDICTION ERROR ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nMean Absolute Error (MAE):\")\n",
    "print(f\"  v1.1 (Calibrated): {mae_v1_1:.3f} points\")\n",
    "print(f\"  v1.0 (Fixed):      {mae_v1_0:.3f} points\")\n",
    "print(f\"  Improvement:       {mae_v1_0 - mae_v1_1:+.3f} points\")\n",
    "\n",
    "print(f\"\\nRoot Mean Squared Error (RMSE):\")\n",
    "print(f\"  v1.1 (Calibrated): {rmse_v1_1:.3f} points\")\n",
    "print(f\"  v1.0 (Fixed):      {rmse_v1_0:.3f} points\")\n",
    "print(f\"  Improvement:       {rmse_v1_0 - rmse_v1_1:+.3f} points\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ats-header",
   "metadata": {},
   "source": [
    "## Section 7: Against-The-Spread (ATS) Backtest\n",
    "\n",
    "Simulate betting strategy:\n",
    "- Only bet when our model disagrees with Vegas by at least X points (edge threshold)\n",
    "- Evaluate win rate and W-L-P record at different thresholds: 1, 2, 3, 4 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ats-backtest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add actual game results (margin from home team perspective)\n",
    "games_df['actual_margin'] = games_df['home_score'] - games_df['away_score']\n",
    "\n",
    "# Filter for games with actual results\n",
    "games_with_results = games_df[games_df['actual_margin'].notna()].copy()\n",
    "\n",
    "print(f\"Games with actual results: {len(games_with_results)} / {len(games_df)}\")\n",
    "\n",
    "if len(games_with_results) == 0:\n",
    "    print(\"\\n‚ö†Ô∏è  No game results available yet for ATS backtest.\")\n",
    "    print(\"This section requires completed games with scores.\")\n",
    "else:\n",
    "    # Calculate edge (model line - vegas line)\n",
    "    games_with_results['edge_v1_1'] = games_with_results['bk_line_v1_1'] - games_with_results['vegas_line']\n",
    "    games_with_results['edge_v1_0'] = games_with_results['bk_line_v1_0'] - games_with_results['vegas_line']\n",
    "    \n",
    "    # Determine if home team covered the spread\n",
    "    # Home covers if: actual_margin + vegas_line > 0\n",
    "    games_with_results['home_covered'] = (games_with_results['actual_margin'] + games_with_results['vegas_line']) > 0\n",
    "    \n",
    "    # Determine which side we would bet on based on edge\n",
    "    # If edge < 0: our model is more favorable to home than Vegas ‚Üí bet home\n",
    "    # If edge > 0: our model is less favorable to home than Vegas ‚Üí bet away\n",
    "    games_with_results['bet_home_v1_1'] = games_with_results['edge_v1_1'] < 0\n",
    "    games_with_results['bet_home_v1_0'] = games_with_results['edge_v1_0'] < 0\n",
    "    \n",
    "    # Edge thresholds to test\n",
    "    EDGE_THRESHOLDS = [1, 2, 3, 4]\n",
    "    \n",
    "    # Results storage\n",
    "    ats_results = []\n",
    "    \n",
    "    for threshold in EDGE_THRESHOLDS:\n",
    "        # Filter games where we have at least 'threshold' edge\n",
    "        bets_v1_1 = games_with_results[games_with_results['edge_v1_1'].abs() >= threshold].copy()\n",
    "        bets_v1_0 = games_with_results[games_with_results['edge_v1_0'].abs() >= threshold].copy()\n",
    "        \n",
    "        # v1.1 results\n",
    "        if len(bets_v1_1) > 0:\n",
    "            bets_v1_1['bet_won'] = bets_v1_1['bet_home_v1_1'] == bets_v1_1['home_covered']\n",
    "            bets_v1_1['bet_push'] = bets_v1_1['actual_margin'] + bets_v1_1['vegas_line'] == 0\n",
    "            \n",
    "            wins_v1_1 = bets_v1_1['bet_won'].sum()\n",
    "            losses_v1_1 = (~bets_v1_1['bet_won'] & ~bets_v1_1['bet_push']).sum()\n",
    "            pushes_v1_1 = bets_v1_1['bet_push'].sum()\n",
    "            total_v1_1 = len(bets_v1_1)\n",
    "            win_rate_v1_1 = wins_v1_1 / total_v1_1 if total_v1_1 > 0 else 0\n",
    "        else:\n",
    "            wins_v1_1 = losses_v1_1 = pushes_v1_1 = total_v1_1 = 0\n",
    "            win_rate_v1_1 = 0\n",
    "        \n",
    "        # v1.0 results\n",
    "        if len(bets_v1_0) > 0:\n",
    "            bets_v1_0['bet_won'] = bets_v1_0['bet_home_v1_0'] == bets_v1_0['home_covered']\n",
    "            bets_v1_0['bet_push'] = bets_v1_0['actual_margin'] + bets_v1_0['vegas_line'] == 0\n",
    "            \n",
    "            wins_v1_0 = bets_v1_0['bet_won'].sum()\n",
    "            losses_v1_0 = (~bets_v1_0['bet_won'] & ~bets_v1_0['bet_push']).sum()\n",
    "            pushes_v1_0 = bets_v1_0['bet_push'].sum()\n",
    "            total_v1_0 = len(bets_v1_0)\n",
    "            win_rate_v1_0 = wins_v1_0 / total_v1_0 if total_v1_0 > 0 else 0\n",
    "        else:\n",
    "            wins_v1_0 = losses_v1_0 = pushes_v1_0 = total_v1_0 = 0\n",
    "            win_rate_v1_0 = 0\n",
    "        \n",
    "        ats_results.append({\n",
    "            'Edge Threshold': f\"{threshold}+ pts\",\n",
    "            'v1.1 Bets': total_v1_1,\n",
    "            'v1.1 Record': f\"{wins_v1_1}-{losses_v1_1}-{pushes_v1_1}\",\n",
    "            'v1.1 Win %': f\"{win_rate_v1_1*100:.1f}%\",\n",
    "            'v1.0 Bets': total_v1_0,\n",
    "            'v1.0 Record': f\"{wins_v1_0}-{losses_v1_0}-{pushes_v1_0}\",\n",
    "            'v1.0 Win %': f\"{win_rate_v1_0*100:.1f}%\"\n",
    "        })\n",
    "    \n",
    "    ats_df = pd.DataFrame(ats_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"ATS BACKTEST RESULTS (Against-The-Spread Performance)\")\n",
    "    print(\"=\"*100)\n",
    "    print(\"\\nBetting Strategy: Only bet when model disagrees with Vegas by >= edge threshold\")\n",
    "    print(\"Record Format: Wins-Losses-Pushes\\n\")\n",
    "    display(ats_df)\n",
    "    print(\"=\"*100)\n",
    "    print(\"\\nNote: Win rate above 52.4% is profitable at -110 odds\")\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Section 8: Summary & Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BALL KNOWER v1.1 - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Training Data:\")\n",
    "print(f\"   Season: {SEASON}\")\n",
    "print(f\"   Weeks: {min(TRAINING_WEEKS)} - {max(TRAINING_WEEKS)}\")\n",
    "print(f\"   Games: {len(games_df)}\")\n",
    "\n",
    "print(f\"\\nüéØ Calibrated Weights:\")\n",
    "print(f\"   nfelo:          {weights['weight_nfelo']:>8.4f}\")\n",
    "print(f\"   substack:       {weights['weight_substack']:>8.4f}\")\n",
    "print(f\"   epa_offensive:  {weights['weight_epa_off']:>8.4f}\")\n",
    "print(f\"   epa_defensive:  {weights['weight_epa_def']:>8.4f}\")\n",
    "print(f\"   bias:           {weights['bias']:>8.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Model Performance:\")\n",
    "print(f\"   Correlation with Vegas: {corr_v1_1:.4f}\")\n",
    "print(f\"   MAE:  {mae_v1_1:.3f} points\")\n",
    "print(f\"   RMSE: {rmse_v1_1:.3f} points\")\n",
    "\n",
    "print(f\"\\n‚úÖ Improvement over v1.0:\")\n",
    "print(f\"   Correlation: {corr_v1_1 - corr_v1_0:+.4f}\")\n",
    "print(f\"   MAE:         {mae_v1_0 - mae_v1_1:+.3f} points\")\n",
    "print(f\"   RMSE:        {rmse_v1_0 - rmse_v1_1:+.3f} points\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Analysis Complete\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Apply to Future Weeks**: Use `build_week_lines_v1_1()` to generate predictions for upcoming games\n",
    "2. **Expand Training Data**: Include more historical seasons for more robust calibration\n",
    "3. **Feature Engineering**: Consider additional components (rest days, QB adjustments, weather)\n",
    "4. **Model v1.2**: Add ML correction layer on top of v1.1 base predictions\n",
    "\n",
    "---\n",
    "\n",
    "**Model Formula (v1.1):**\n",
    "\n",
    "```\n",
    "spread = w‚ÇÅ¬∑nfelo_diff + w‚ÇÇ¬∑substack_diff + w‚ÇÉ¬∑epa_off_diff + w‚ÇÑ¬∑epa_def_diff + bias\n",
    "```\n",
    "\n",
    "Where weights are learned from historical Vegas lines via OLS regression.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
