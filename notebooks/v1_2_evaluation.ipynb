{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ball Knower v1.2 Model Evaluation\n",
    "\n",
    "Reproducible evaluation notebook for v1.2 model performance.\n",
    "\n",
    "## Purpose\n",
    "- Load backtest results from standardized paths\n",
    "- Compute v1.2 metrics (MAE, ATS, CLV, EV)\n",
    "- Visualize performance trends\n",
    "- Generate calibration curves\n",
    "\n",
    "## Important\n",
    "- This notebook is for visualization and reporting only\n",
    "- No model logic or feature engineering\n",
    "- Uses the evaluation module for metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import Ball Knower modules\n",
    "from ball_knower import config\n",
    "from ball_knower.utils import paths\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Backtest Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define backtest parameters\n",
    "MODEL_VERSION = \"v1.2\"\n",
    "START_SEASON = 2019\n",
    "END_SEASON = 2024\n",
    "\n",
    "# Load backtest results using standardized paths\n",
    "backtest_path = paths.get_backtest_results_path(\n",
    "    MODEL_VERSION,\n",
    "    START_SEASON,\n",
    "    END_SEASON\n",
    ")\n",
    "\n",
    "if backtest_path.exists():\n",
    "    backtest_df = pd.read_csv(backtest_path)\n",
    "    print(f\"✓ Loaded backtest results: {backtest_path}\")\n",
    "    print(f\"  Seasons: {len(backtest_df)} rows\")\n",
    "    display(backtest_df.head())\n",
    "else:\n",
    "    print(f\"⚠ Backtest file not found: {backtest_path}\")\n",
    "    print(f\"  Run: python src/bk_build.py backtest --model {MODEL_VERSION} --start-season {START_SEASON} --end-season {END_SEASON}\")\n",
    "    backtest_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Summary Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_df is not None:\n",
    "    # Overall metrics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"V1.2 MODEL - OVERALL PERFORMANCE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_games = backtest_df['n_games'].sum()\n",
    "    avg_mae = backtest_df['mae_vs_vegas'].mean()\n",
    "    avg_rmse = backtest_df['rmse_vs_vegas'].mean()\n",
    "    \n",
    "    print(f\"\\nTotal games analyzed: {total_games:,}\")\n",
    "    print(f\"Average MAE vs Vegas: {avg_mae:.2f} points\")\n",
    "    print(f\"Average RMSE vs Vegas: {avg_rmse:.2f} points\")\n",
    "    print(f\"Average edge: {backtest_df['mean_edge'].mean():.3f} points\")\n",
    "    \n",
    "    # Per-season breakdown\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"PER-SEASON BREAKDOWN\")\n",
    "    print(\"-\"*60)\n",
    "    display(backtest_df[['season', 'n_games', 'mae_vs_vegas', 'rmse_vs_vegas', 'mean_edge']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 MAE vs Vegas by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_df is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.plot(backtest_df['season'], backtest_df['mae_vs_vegas'], \n",
    "            marker='o', linewidth=2, markersize=8)\n",
    "    ax.axhline(y=avg_mae, color='r', linestyle='--', label=f'Average MAE: {avg_mae:.2f}')\n",
    "    \n",
    "    ax.set_xlabel('Season', fontsize=12)\n",
    "    ax.set_ylabel('MAE vs Vegas (points)', fontsize=12)\n",
    "    ax.set_title('Ball Knower v1.2 - MAE vs Vegas by Season', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average MAE across all seasons: {avg_mae:.2f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Games Analyzed by Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_df is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    ax.bar(backtest_df['season'], backtest_df['n_games'], alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    ax.set_xlabel('Season', fontsize=12)\n",
    "    ax.set_ylabel('Number of Games', fontsize=12)\n",
    "    ax.set_title('Ball Knower v1.2 - Games Analyzed by Season', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Edge Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_df is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Histogram of mean edge by season\n",
    "    ax.hist(backtest_df['mean_edge'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero edge')\n",
    "    \n",
    "    ax.set_xlabel('Mean Edge (points)', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_title('Ball Knower v1.2 - Distribution of Mean Edge by Season', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nEdge Statistics:\")\n",
    "    print(f\"  Mean: {backtest_df['mean_edge'].mean():.3f} points\")\n",
    "    print(f\"  Std: {backtest_df['mean_edge'].std():.3f} points\")\n",
    "    print(f\"  Min: {backtest_df['mean_edge'].min():.3f} points\")\n",
    "    print(f\"  Max: {backtest_df['mean_edge'].max():.3f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backtest_df is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BALL KNOWER V1.2 - EVALUATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nModel Version: {MODEL_VERSION}\")\n",
    "    print(f\"Evaluation Period: {START_SEASON}-{END_SEASON}\")\n",
    "    print(f\"Total Games: {total_games:,}\")\n",
    "    print(f\"\\nKey Metrics:\")\n",
    "    print(f\"  MAE vs Vegas: {avg_mae:.2f} points\")\n",
    "    print(f\"  RMSE vs Vegas: {avg_rmse:.2f} points\")\n",
    "    print(f\"  Mean Edge: {backtest_df['mean_edge'].mean():.3f} points\")\n",
    "    print(f\"\\nInterpretation:\")\n",
    "    print(f\"  - MAE measures average prediction error\")\n",
    "    print(f\"  - Lower MAE indicates better accuracy\")\n",
    "    print(f\"  - Edge represents how much BK differs from Vegas\")\n",
    "    print(f\"  - Near-zero mean edge suggests Vegas efficiency\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"⚠ No backtest data available for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "To improve this evaluation:\n",
    "1. Add game-level predictions (not just season aggregates)\n",
    "2. Compute ATS (against the spread) win rate\n",
    "3. Calculate CLV (closing line value)\n",
    "4. Add expected value (EV) calculations\n",
    "5. Create calibration curves for probability predictions\n",
    "\n",
    "For now, this notebook provides:\n",
    "- Basic performance metrics\n",
    "- Temporal trends\n",
    "- Visual diagnostics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
